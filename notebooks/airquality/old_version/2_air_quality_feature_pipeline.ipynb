{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /home/olive/dev/lab1A\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "if os.path.exists(f\"{root_dir}/.env\"):\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_info_hopsworks(street):\n",
    "    project = hopsworks.login()\n",
    "    fs = project.get_feature_store() \n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "    \n",
    "    # This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "    AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "    location_str = secrets.get_secret(f\"SENSOR_LOCATION_JSON_{street.lower()}\").value\n",
    "    location = json.loads(location_str)\n",
    "    \n",
    "    country=location['country']\n",
    "    city=location['city']\n",
    "    street=location['street']\n",
    "    aqicn_url=location['aqicn_url']\n",
    "    latitude=location['latitude']\n",
    "    longitude=location['longitude']\n",
    "    \n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    location_str\n",
    "    return project, fs, AQICN_API_KEY, country, city, street, aqicn_url, latitude, longitude, today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "def fetch_fgs(street, fs):\n",
    "    air_quality_fg = fs.get_feature_group(\n",
    "        name=f\"air_quality_v_agrade_{street.lower()}\",\n",
    "        version=1,\n",
    "    )\n",
    "    weather_fg = fs.get_feature_group(\n",
    "        name=f\"weather_v_agrade_{street.lower()}\",\n",
    "        version=1,\n",
    "    )\n",
    "    return air_quality_fg, weather_fg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_aq_today(aqicn_url, country, city, street, today, AQICN_API_KEY):\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "    aq_today_df\n",
    "    \n",
    "    return aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8514062-a022-4c80-87e2-341ed557de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW. NEED TO ADD ROLLING FROM PREVIOUS TO THIS DAY\n",
    "# FETCH LAST THREE PM25s FROM df\n",
    "def add_rollings_today(air_quality_fg,today,aq_today_df):\n",
    "    import time\n",
    "    #query = air_quality_fg.select_all().filter(air_quality_fg[\"date\"] >= datetime.date.today()-datetime.timedelta(days=4))\n",
    "    \n",
    "    #df_recent = query.read()\n",
    "    #print(df_recent)\n",
    "    #aq_today_df[\"roll\"] = df_recent[\"pm25\"].mean().astype(\"float64\")\n",
    "    #aq_today_df = aq_today_df[[\"date\",\"pm25\",\"roll\",\"country\",\"city\",\"street\",\"url\"]]\n",
    "    #aq_today_df\n",
    "    query = air_quality_fg.select_all().filter(air_quality_fg['date']>= today-datetime.timedelta(days=4))\n",
    "    \n",
    "    df_recent = query.read()\n",
    "    \n",
    "    df_recent = df_recent.sort_values('date')\n",
    "    print(df_recent)\n",
    "    pm_prev3 = df_recent['pm25'].head(3)\n",
    "    aq_today_df['rolling3'] = pm_prev3.mean()\n",
    "    \n",
    "    aq_today_df['lag1d'] = df_recent['pm25'].iloc[2]\n",
    "    aq_today_df['lag2d'] = df_recent['pm25'].iloc[1]\n",
    "    aq_today_df['lag3d'] = df_recent['pm25'].iloc[0]\n",
    "    \n",
    "    \n",
    "    aq_today_df \n",
    "    \n",
    "    return aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_forecast(city, latitude, longitude):\n",
    "    hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "    hourly_df = hourly_df.set_index('date')\n",
    "    \n",
    "    # We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "    # We only want the daily weather data, so only get weather at 12:00\n",
    "    daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "    daily_df = daily_df.reset_index()\n",
    "    daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "    daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "    daily_df['city'] = city\n",
    "    daily_df\n",
    "    \n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c563109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aq_insert_new_data(air_quality_fg,aq_today_df):\n",
    "    # Insert new data\n",
    "    air_quality_fg.insert(aq_today_df)\n",
    "\n",
    "    return air_quality_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new data\n",
    "def weather_insert(weather_fg, daily_df):\n",
    "    weather_fg.insert(daily_df, wait=True)\n",
    "\n",
    "    return weather_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4fb45ed-3faf-4dbc-a580-90d3fbf43eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:05:24,791 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-15 15:05:24,793 INFO: Initializing external client\n",
      "2025-11-15 15:05:24,794 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:05:26,138 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286329\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.59s) \n",
      "                       date  pm25   rolling3  lag1d  lag2d  lag3d country  \\\n",
      "0 2025-11-12 00:00:00+00:00  27.0  25.000000   21.0   23.0   31.0   Japan   \n",
      "3 2025-11-13 00:00:00+00:00  34.0  23.666666   27.0   21.0   23.0   Japan   \n",
      "1 2025-11-14 00:00:00+00:00  46.0  27.333334   34.0   27.0   21.0   Japan   \n",
      "2 2025-11-15 00:00:00+00:00  39.0  35.666668   46.0   34.0   27.0   Japan   \n",
      "\n",
      "        city    street                               url  \n",
      "0  Toyohashi  imahashi  https://api.waqi.info/feed/@2543  \n",
      "3  Toyohashi  imahashi  https://api.waqi.info/feed/@2543  \n",
      "1  Toyohashi  imahashi  https://api.waqi.info/feed/@2543  \n",
      "2  Toyohashi  imahashi  https://api.waqi.info/feed/@2543  \n",
      "Coordinates 34.75¬∞N 137.5¬∞E\n",
      "Elevation 12.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-15 15:05:32,408 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1703559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_v_agrade_imahashi_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/air_quality_v_agrade_imahashi_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:05:44,942 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1703561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_v_agrade_imahashi_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/weather_v_agrade_imahashi_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:06:03,646 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 15:06:06,805 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-15 15:07:43,640 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-15 15:07:43,791 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-15 15:07:52,328 INFO: Execution finished successfully.\n",
      "2025-11-15 15:07:52,330 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-15 15:07:52,332 INFO: Initializing external client\n",
      "2025-11-15 15:07:52,332 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:07:53,917 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286329\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.67s) \n",
      "                       date  pm25   rolling3  lag1d  lag2d  lag3d country  \\\n",
      "0 2025-11-12 00:00:00+00:00  31.0  24.666666   16.0   13.0   45.0   Japan   \n",
      "3 2025-11-13 00:00:00+00:00  36.0  20.000000   31.0   16.0   13.0   Japan   \n",
      "1 2025-11-14 00:00:00+00:00  29.0  27.666666   36.0   31.0   16.0   Japan   \n",
      "2 2025-11-15 00:00:00+00:00  29.0  32.000000   29.0   36.0   31.0   Japan   \n",
      "\n",
      "        city street                               url  \n",
      "0  Toyohashi  azuma  https://api.waqi.info/feed/@2374  \n",
      "3  Toyohashi  azuma  https://api.waqi.info/feed/@2374  \n",
      "1  Toyohashi  azuma  https://api.waqi.info/feed/@2374  \n",
      "2  Toyohashi  azuma  https://api.waqi.info/feed/@2374  \n",
      "Coordinates 34.75¬∞N 137.5¬∞E\n",
      "Elevation 24.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-15 15:08:04,550 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1718637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_v_agrade_azuma_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/air_quality_v_agrade_azuma_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:08:19,834 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1703562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_v_agrade_azuma_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/weather_v_agrade_azuma_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:08:35,035 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 15:08:38,185 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-15 15:10:21,030 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-15 15:10:21,169 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-15 15:10:31,375 INFO: Execution finished successfully.\n",
      "2025-11-15 15:10:31,378 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-15 15:10:31,381 INFO: Initializing external client\n",
      "2025-11-15 15:10:31,381 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:10:32,651 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286329\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.57s) \n",
      "                       date  pm25   rolling3  lag1d  lag2d  lag3d country  \\\n",
      "1 2025-11-12 00:00:00+00:00  29.0  30.666666   29.0   30.0   33.0   Japan   \n",
      "2 2025-11-13 00:00:00+00:00  41.0  29.333334   29.0   29.0   30.0   Japan   \n",
      "0 2025-11-14 00:00:00+00:00  47.0  33.000000   41.0   29.0   29.0   Japan   \n",
      "3 2025-11-15 00:00:00+00:00  43.0  39.000000   47.0   41.0   29.0   Japan   \n",
      "\n",
      "        city street                               url  \n",
      "1  Toyohashi  osaki  https://api.waqi.info/feed/@2372  \n",
      "2  Toyohashi  osaki  https://api.waqi.info/feed/@2372  \n",
      "0  Toyohashi  osaki  https://api.waqi.info/feed/@2372  \n",
      "3  Toyohashi  osaki  https://api.waqi.info/feed/@2372  \n",
      "Coordinates 34.75¬∞N 137.5¬∞E\n",
      "Elevation 14.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-15 15:10:38,723 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1703564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_v_agrade_osaki_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/air_quality_v_agrade_osaki_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:10:51,234 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1718638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_v_agrade_osaki_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/weather_v_agrade_osaki_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:11:09,326 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 15:12:32,176 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-15 15:14:54,465 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: UNDEFINED\n",
      "2025-11-15 15:14:59,360 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2025-11-15 15:14:59,724 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-15 15:14:59,725 INFO: Execution finished successfully.\n",
      "2025-11-15 15:14:59,726 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-15 15:14:59,728 INFO: Initializing external client\n",
      "2025-11-15 15:14:59,729 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:15:01,095 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286329\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.87s) \n",
      "                       date  pm25   rolling3  lag1d  lag2d  lag3d country  \\\n",
      "1 2025-11-12 00:00:00+00:00  29.0  30.666666   29.0   30.0   33.0   Japan   \n",
      "2 2025-11-13 00:00:00+00:00  41.0  29.333334   29.0   29.0   30.0   Japan   \n",
      "0 2025-11-14 00:00:00+00:00  47.0  33.000000   41.0   29.0   29.0   Japan   \n",
      "3 2025-11-15 00:00:00+00:00  37.0  39.000000   47.0   41.0   29.0   Japan   \n",
      "\n",
      "        city  street                               url  \n",
      "1  Toyohashi  noyori  https://api.waqi.info/feed/@6600  \n",
      "2  Toyohashi  noyori  https://api.waqi.info/feed/@6600  \n",
      "0  Toyohashi  noyori  https://api.waqi.info/feed/@6600  \n",
      "3  Toyohashi  noyori  https://api.waqi.info/feed/@6600  \n",
      "Coordinates 34.75¬∞N 137.5¬∞E\n",
      "Elevation 22.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-15 15:15:07,246 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1718639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_v_agrade_noyori_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/air_quality_v_agrade_noyori_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:15:19,754 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1718640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_v_agrade_noyori_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/weather_v_agrade_noyori_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:15:38,001 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 15:16:03,360 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-15 15:17:40,461 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2025-11-15 15:17:40,858 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-15 15:17:40,858 INFO: Execution finished successfully.\n",
      "2025-11-15 15:17:40,859 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-15 15:17:40,861 INFO: Initializing external client\n",
      "2025-11-15 15:17:40,862 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:17:42,213 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286329\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
      "                       date  pm25   rolling3  lag1d  lag2d  lag3d country  \\\n",
      "1 2025-11-12 00:00:00+00:00  28.0  28.333334   25.0   28.0   32.0   Japan   \n",
      "3 2025-11-13 00:00:00+00:00  39.0  27.000000   28.0   25.0   28.0   Japan   \n",
      "2 2025-11-14 00:00:00+00:00  47.0  30.666666   39.0   28.0   25.0   Japan   \n",
      "0 2025-11-15 00:00:00+00:00  41.0  38.000000   47.0   39.0   28.0   Japan   \n",
      "\n",
      "        city street                               url  \n",
      "1  Toyohashi   oiwa  https://api.waqi.info/feed/@2373  \n",
      "3  Toyohashi   oiwa  https://api.waqi.info/feed/@2373  \n",
      "2  Toyohashi   oiwa  https://api.waqi.info/feed/@2373  \n",
      "0  Toyohashi   oiwa  https://api.waqi.info/feed/@2373  \n",
      "Coordinates 34.75¬∞N 137.5¬∞E\n",
      "Elevation 24.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-15 15:17:49,944 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1718641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_v_agrade_oiwa_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/air_quality_v_agrade_oiwa_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:18:02,497 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286329/fs/1273951/fg/1703565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_v_agrade_oiwa_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286329/jobs/named/weather_v_agrade_oiwa_1_offline_fg_materialization/executions\n",
      "2025-11-15 15:18:18,291 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 15:19:09,267 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-15 15:20:35,166 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-15 15:20:35,321 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-15 15:20:45,730 INFO: Execution finished successfully.\n"
     ]
    }
   ],
   "source": [
    "locations = {\n",
    "                \"imahashi\":\n",
    "                    {\n",
    "                        \"url\":\"https://api.waqi.info/feed/@2543\",\n",
    "                        \"lat\":\"34.766389\", \n",
    "                        \"long\":\"137.393889\"\n",
    "                    },\n",
    "                \"azuma\": \n",
    "                    {\n",
    "                        \"url\":\"https://api.waqi.info/feed/@2374\",\n",
    "                        \"lat\":\"34.7632176\",\n",
    "                        \"long\":\"137.4145777\"\n",
    "                    },\n",
    "                \"osaki\": \n",
    "                    {\n",
    "                        \"url\":\"https://api.waqi.info/feed/@2372\",\n",
    "                        \"lat\":\"34.712222\",\n",
    "                        \"long\":\"137.346944\"\n",
    "                    },\n",
    "                \"noyori\": \n",
    "                    {\n",
    "                        \"url\":\"https://api.waqi.info/feed/@6600\",\n",
    "                        \"lat\":\"34.698889\", \n",
    "                        \"long\":\"137.39\"\n",
    "                    },\n",
    "                \"oiwa\": \n",
    "                    {\n",
    "                        \"url\":\"https://api.waqi.info/feed/@2373\",\n",
    "                        \"lat\":\"34.721944\", \n",
    "                        \"long\":\"137.450833\"\n",
    "                    }\n",
    "            }\n",
    "\n",
    "def full_pipeline(stations):\n",
    "    \n",
    "    for location in stations:\n",
    "\n",
    "        street = location\n",
    "    \n",
    "        project, fs, AQICN_API_KEY, country, city, street, url, latitude, longitude, today = get_info_hopsworks(street)\n",
    "    \n",
    "        air_quality_fg, weather_fg = fetch_fgs(street, fs)\n",
    "        \n",
    "        aq_today_df = retrieve_aq_today(url, country, city, street, today, AQICN_API_KEY)\n",
    "    \n",
    "        aq_today_df = add_rollings_today(air_quality_fg,today,aq_today_df)\n",
    "    \n",
    "        daily_df = get_weather_forecast(city, latitude, longitude)\n",
    "    \n",
    "        air_quality_fg = aq_insert_new_data(air_quality_fg,aq_today_df)\n",
    "    \n",
    "        weather_fg = weather_insert(weather_fg, daily_df)\n",
    "\n",
    "    \n",
    "full_pipeline(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "190ea7959a836f4799545ea0f3718ade3abee093b15861ffdc25233d6ab7050e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
